{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_from_database_full as dfd\n",
    "import nltk\n",
    "import numpy\n",
    "import pandas\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Mengambil data dari database\n",
    "dataset_document_word, dataset_tag_document = dfd.get_data()\n",
    "# dataset_tag_document = dfd.get_document_and_tag()\n",
    "\n",
    "# Tempat untuk menghitung banyaknya word dalam suatu dokumen\n",
    "dataframe_document_word = []\n",
    "\n",
    "def wordProcessing(content_article):\n",
    "    \"\"\"\n",
    "    Fungsi untuk menghitung 'word' dalam suatu artikel\n",
    "    \"\"\"\n",
    "    tokens = word_tokenize(re.sub('[^ 0-9a-z]+', ' ', content_article.lower())) # Menghilangkan tanda baca   \n",
    "    english_stopwords = stopwords.words('english') # Menghilangkan stop words\n",
    "    english_stopwords.extend(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'])\n",
    "    tokens_wo_stopwords = [t for t in tokens if t not in english_stopwords]\n",
    "\n",
    "    # Menghitung banyaknya tokens\n",
    "    freq = nltk.FreqDist(tokens_wo_stopwords)\n",
    "    word_document_dictionary = {}\n",
    "\n",
    "    # Menampung token tersebut dalam format dictionary\n",
    "    for word, count in freq.most_common(999999):\n",
    "        word_document_dictionary.update({word: count})\n",
    "    \n",
    "    return word_document_dictionary\n",
    "\n",
    "def documentWordProcessing(content_article, title_article):\n",
    "    \"\"\"\n",
    "    Fungsi untuk membuat dataframe antara 'document' dengan 'word'\n",
    "    \"\"\"\n",
    "    word_document_dictionary = wordProcessing(content_article)\n",
    "    datafr = pandas.DataFrame(word_document_dictionary,\n",
    "        index=[title_article]\n",
    "    )\n",
    "    return datafr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_tag_processing(dataset_tag_document):  \n",
    "  title_before = dataset_tag_document[0][1]\n",
    "  \n",
    "  tag_dictionary = {}\n",
    "  # Tempat untuk menghitung banyaknya tag dalam suatu dokumen\n",
    "  dataframe_document_tag = []\n",
    "  \n",
    "  for data in dataset_tag_document:\n",
    "    # Jika judul dokumen berbeda dengan row sebelumnya\n",
    "    if title_before != data[1]:\n",
    "      datafr = pandas.DataFrame(tag_dictionary,\n",
    "          index=[title_before]\n",
    "      )\n",
    "      dataframe_document_tag.append(datafr)\n",
    "      title_before = data[1]\n",
    "      tag_dictionary.clear()\n",
    "    \n",
    "    tag_dictionary.update({data[0]: 1})\n",
    "\n",
    "  datafr = pandas.DataFrame(tag_dictionary,\n",
    "      index=[title_before]\n",
    "  )\n",
    "  dataframe_document_tag.append(datafr)\n",
    "  tag_dictionary.clear()\n",
    "  \n",
    "  return dataframe_document_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_document_tag_join = pandas.concat(document_tag_processing(dataset_tag_document))\n",
    "dataframe_document_tag_join = dataframe_document_tag_join.fillna(0)\n",
    "# print(dataframe_document_tag_join)\n",
    "dataframe_document_tag_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataset_document_word:\n",
    "    dataframe_document_word.append(documentWordProcessing(data[1], data[0]))\n",
    "\n",
    "dataframe_document_word_join = pandas.concat(dataframe_document_word)\n",
    "dataframe_document_word_join = dataframe_document_word_join.fillna(0)\n",
    "dataframe_document_word_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def matrixABtoW(A, B):\n",
    "    \"\"\"\n",
    "    Fungsi untuk memasukkan matriks A, A transpose, B, dan B transpose ke dalam matriks W\n",
    "    \"\"\"\n",
    "    AT = A.transpose()\n",
    "    BT = B.transpose()\n",
    "\n",
    "    tag_count, document_count = A.shape\n",
    "    document_count, word_count = B.shape\n",
    "\n",
    "    all_count = tag_count + document_count + word_count\n",
    "    W = numpy.zeros((all_count, all_count))\n",
    "\n",
    "    # Menempelkan matriks A ke W\n",
    "    for i in range(tag_count):\n",
    "        W[i][tag_count:-word_count] = A[i]\n",
    "\n",
    "    # Menempelkan matriks B Transpose ke W\n",
    "    for i in range(1, word_count+1):\n",
    "        W[-i][tag_count:-word_count]= BT[-i]\n",
    "\n",
    "    # Menempelkan matriks A Transpose ke W\n",
    "    for i in range(document_count):\n",
    "        W[tag_count+i][0:tag_count] = AT[i]\n",
    "        \n",
    "    # Menempelkan matriks B ke W\n",
    "    for i in range(document_count):\n",
    "        W[tag_count+i][-word_count:] = B[i]\n",
    "    \n",
    "    return W\n",
    "\n",
    "# print(dataframe_document_word_join.to_numpy())\n",
    "# print(dataframe_document_tag_join.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_w = matrixABtoW(dataframe_document_tag_join.to_numpy().transpose(), dataframe_document_word_join.to_numpy())\n",
    "matrix_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_w.max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
